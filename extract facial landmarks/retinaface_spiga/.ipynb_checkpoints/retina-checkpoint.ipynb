{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b928e0-cae3-4ba0-9a81-fd2a2a5c2332",
   "metadata": {},
   "source": [
    "# Retinaface로 bbox 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8469b6d7-b58a-4434-94fa-85831c3eb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install onnxruntime-gpu #그냥 onnxruntime말고 onnxruntime-gpu로 설치해야 cuda 동작가능\n",
    "\n",
    "pip install insightface\n",
    "\n",
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a2847a-8ede-4336-a90d-8c4a97c35bf8",
   "metadata": {},
   "source": [
    "[주의] <br>\n",
    "https://forums.developer.nvidia.com/t/could-not-load-library-cudnn-cnn-infer64-8-dll-error-code-193/218437/16<br>\n",
    "여기서 zlib123dllx64.zip 파일 다운 받은 후에 압축 풀어서 zlibwapi.dll파일을  c:/program files/nvidia gpu computin toolkit/cuda/v11.6/bin폴더에 복사해서 넣어줘야 cuda 동작됨. (v11.6은 우리가 설치한 버전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a001e39-dd7f-444b-8b1f-18da4c8d014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\오민준/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\오민준/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\오민준/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\오민준/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\오민준/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nanodet\\lib\\site-packages\\insightface\\utils\\transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 이미지에 대한 bbox 정보 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# FaceAnalysis 객체 초기화\n",
    "app = FaceAnalysis(providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640)) #ctx_id=0으로 설정해야 0번째 gpu사용\n",
    "\n",
    "input_folder = 'omg_1min'  # 입력 이미지가 있는 폴더\n",
    "bbox_folder = 'bbox_data'  # bbox 정보를 저장할 폴더\n",
    "\n",
    "# bbox 폴더가 없으면 생성\n",
    "if not os.path.exists(bbox_folder):\n",
    "    os.makedirs(bbox_folder)\n",
    "\n",
    "# 입력 폴더에서 이미지 파일 목록 가져오기\n",
    "image_files = [f for f in os.listdir(input_folder) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "# 각 이미지에 대한 처리 및 bbox 정보 저장\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(input_folder, image_file)\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # 얼굴 감지\n",
    "    faces = app.get(img)\n",
    "    \n",
    "    # 감지된 얼굴에 대한 bbox 정보 저장\n",
    "    bboxes = [face.bbox.astype(int).tolist() for face in faces]\n",
    "    \n",
    "    # bbox 정보 저장\n",
    "    bbox_file_path = os.path.join(bbox_folder, image_file.replace('.jpg', '.json'))\n",
    "    with open(bbox_file_path, 'w') as f:\n",
    "        json.dump({\"bbox\": bboxes}, f)\n",
    "\n",
    "print(\"모든 이미지에 대한 bbox 정보 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af55bd-92d7-4309-a9ff-f6dfcde6880c",
   "metadata": {},
   "source": [
    "# SPIGA로 facial landmark 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37399a5-a446-47c1-bbed-3092c5f1efb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\오민준\\Desktop\\2401CapstoneDesign\\extract facial landmarks\\retinaface\\SPIGA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'SPIGA'...\n",
      "Updating files:   9% (11/120)\n",
      "Updating files:  10% (12/120)\n",
      "Updating files:  11% (14/120)\n",
      "Updating files:  12% (15/120)\n",
      "Updating files:  13% (16/120)\n",
      "Updating files:  14% (17/120)\n",
      "Updating files:  15% (18/120)\n",
      "Updating files:  16% (20/120)\n",
      "Updating files:  17% (21/120)\n",
      "Updating files:  18% (22/120)\n",
      "Updating files:  19% (23/120)\n",
      "Updating files:  20% (24/120)\n",
      "Updating files:  21% (26/120)\n",
      "Updating files:  22% (27/120)\n",
      "Updating files:  23% (28/120)\n",
      "Updating files:  24% (29/120)\n",
      "Updating files:  25% (30/120)\n",
      "Updating files:  26% (32/120)\n",
      "Updating files:  27% (33/120)\n",
      "Updating files:  28% (34/120)\n",
      "Updating files:  29% (35/120)\n",
      "Updating files:  30% (36/120)\n",
      "Updating files:  31% (38/120)\n",
      "Updating files:  32% (39/120)\n",
      "Updating files:  33% (40/120)\n",
      "Updating files:  34% (41/120)\n",
      "Updating files:  35% (42/120)\n",
      "Updating files:  36% (44/120)\n",
      "Updating files:  37% (45/120)\n",
      "Updating files:  38% (46/120)\n",
      "Updating files:  39% (47/120)\n",
      "Updating files:  40% (48/120)\n",
      "Updating files:  41% (50/120)\n",
      "Updating files:  42% (51/120)\n",
      "Updating files:  43% (52/120)\n",
      "Updating files:  44% (53/120)\n",
      "Updating files:  45% (54/120)\n",
      "Updating files:  46% (56/120)\n",
      "Updating files:  47% (57/120)\n",
      "Updating files:  48% (58/120)\n",
      "Updating files:  49% (59/120)\n",
      "Updating files:  50% (60/120)\n",
      "Updating files:  51% (62/120)\n",
      "Updating files:  52% (63/120)\n",
      "Updating files:  53% (64/120)\n",
      "Updating files:  54% (65/120)\n",
      "Updating files:  55% (66/120)\n",
      "Updating files:  56% (68/120)\n",
      "Updating files:  57% (69/120)\n",
      "Updating files:  58% (70/120)\n",
      "Updating files:  59% (71/120)\n",
      "Updating files:  60% (72/120)\n",
      "Updating files:  61% (74/120)\n",
      "Updating files:  62% (75/120)\n",
      "Updating files:  63% (76/120)\n",
      "Updating files:  64% (77/120)\n",
      "Updating files:  65% (78/120)\n",
      "Updating files:  66% (80/120)\n",
      "Updating files:  67% (81/120)\n",
      "Updating files:  68% (82/120)\n",
      "Updating files:  69% (83/120)\n",
      "Updating files:  70% (84/120)\n",
      "Updating files:  71% (86/120)\n",
      "Updating files:  72% (87/120)\n",
      "Updating files:  73% (88/120)\n",
      "Updating files:  74% (89/120)\n",
      "Updating files:  75% (90/120)\n",
      "Updating files:  76% (92/120)\n",
      "Updating files:  77% (93/120)\n",
      "Updating files:  78% (94/120)\n",
      "Updating files:  79% (95/120)\n",
      "Updating files:  80% (96/120)\n",
      "Updating files:  81% (98/120)\n",
      "Updating files:  82% (99/120)\n",
      "Updating files:  83% (100/120)\n",
      "Updating files:  84% (101/120)\n",
      "Updating files:  85% (102/120)\n",
      "Updating files:  86% (104/120)\n",
      "Updating files:  87% (105/120)\n",
      "Updating files:  88% (106/120)\n",
      "Updating files:  89% (107/120)\n",
      "Updating files:  90% (108/120)\n",
      "Updating files:  91% (110/120)\n",
      "Updating files:  92% (111/120)\n",
      "Updating files:  93% (112/120)\n",
      "Updating files:  94% (113/120)\n",
      "Updating files:  95% (114/120)\n",
      "Updating files:  96% (116/120)\n",
      "Updating files:  97% (117/120)\n",
      "Updating files:  98% (118/120)\n",
      "Updating files:  99% (119/120)\n",
      "Updating files: 100% (120/120)\n",
      "Updating files: 100% (120/120), done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/%EC%98%A4%EB%AF%BC%EC%A4%80/Desktop/2401CapstoneDesign/extract%20facial%20landmarks/retinaface/SPIGA\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=3.2.1 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from spiga==0.0.6) (3.7.5)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from spiga==0.0.6) (1.24.4)\n",
      "Requirement already satisfied: opencv-python>=4.2.0.32 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from spiga==0.0.6) (4.9.0.80)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from spiga==0.0.6) (10.2.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from spiga==0.0.6) (1.13.1)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from spiga==0.0.6) (0.14.1)\n",
      "Requirement already satisfied: torchaudio in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from spiga==0.0.6) (0.13.1)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from spiga==0.0.6) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from spiga==0.0.6) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib>=3.2.1->spiga==0.0.6) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib>=3.2.1->spiga==0.0.6) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib>=3.2.1->spiga==0.0.6) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib>=3.2.1->spiga==0.0.6) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib>=3.2.1->spiga==0.0.6) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib>=3.2.1->spiga==0.0.6) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib>=3.2.1->spiga==0.0.6) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib>=3.2.1->spiga==0.0.6) (6.3.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from torch>=1.4.0->spiga==0.0.6) (4.9.0)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from torchvision>=0.5.0->spiga==0.0.6) (2.31.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from scikit-learn->spiga==0.0.6) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from scikit-learn->spiga==0.0.6) (3.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.1->spiga==0.0.6) (3.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\오민준\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.1->spiga==0.0.6) (1.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from requests->torchvision>=0.5.0->spiga==0.0.6) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from requests->torchvision>=0.5.0->spiga==0.0.6) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from requests->torchvision>=0.5.0->spiga==0.0.6) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\envs\\nanodet\\lib\\site-packages (from requests->torchvision>=0.5.0->spiga==0.0.6) (2024.2.2)\n",
      "Building wheels for collected packages: spiga\n",
      "  Building editable for spiga (pyproject.toml): started\n",
      "  Building editable for spiga (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for spiga: filename=spiga-0.0.6-0.editable-py3-none-any.whl size=8097 sha256=49ed3e68229ea6e4e4d1467f7e4a4b4c3d894d22859768d3a4516d45afd77954\n",
      "  Stored in directory: C:\\Users\\오민준\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-66zv6oz1\\wheels\\d4\\2a\\8a\\dee15a11169b80a27374c5321edc505610ba696090e8fcb05e\n",
      "Successfully built spiga\n",
      "Installing collected packages: spiga\n",
      "  Attempting uninstall: spiga\n",
      "    Found existing installation: spiga 0.0.6\n",
      "    Uninstalling spiga-0.0.6:\n",
      "      Successfully uninstalled spiga-0.0.6\n",
      "Successfully installed spiga-0.0.6\n"
     ]
    }
   ],
   "source": [
    "# Clone and setup the repository\n",
    "!git clone https://github.com/andresprados/SPIGA.git\n",
    "%cd SPIGA/\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d3a8be-970d-4445-a3f2-828de3901164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://drive.google.com/uc?export=download&confirm=yes&id=1h0qA5ysKorpeDNRXe9oYkVcVe8UYyzP7\" to C:\\Users\\오민준\\Desktop\\2401CapstoneDesign\\extract facial landmarks\\retinaface\\SPIGA\\spiga\\models\\weights\\spiga_wflw.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aca0d015bfd441da20ffee71b27f75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/2.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '<'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_file \u001b[38;5;129;01min\u001b[39;00m img_files:\n\u001b[0;32m     62\u001b[0m     bbox_file \u001b[38;5;241m=\u001b[39m img_file\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m     \u001b[43mprocess_and_save_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox_data_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m모든 이미지의 처리 및 저장이 완료되었습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 29\u001b[0m, in \u001b[0;36mprocess_and_save_image\u001b[1;34m(image_path, bbox_path, output_path)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bbox_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# SPIGA 프로세스 실행\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwflw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 29\u001b[0m     processor \u001b[38;5;241m=\u001b[39m \u001b[43mSPIGAFramework\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModelConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     features \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39minference(image, [bbox])\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# 결과 이미지 준비\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\2401CapstoneDesign\\extract facial landmarks\\retinaface\\SPIGA\\spiga\\inference\\framework.py:37\u001b[0m, in \u001b[0;36mSPIGAFramework.__init__\u001b[1;34m(self, model_cfg, gpus, load3DM)\u001b[0m\n\u001b[0;32m     34\u001b[0m     weights_path \u001b[38;5;241m=\u001b[39m weights_path_dft\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_cfg\u001b[38;5;241m.\u001b[39mload_model_url:\n\u001b[1;32m---> 37\u001b[0m     model_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_weights_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     weights_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(weights_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_cfg\u001b[38;5;241m.\u001b[39mmodel_weights)\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\nanodet\\lib\\site-packages\\torch\\hub.py:735\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[1;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location)\n\u001b[1;32m--> 735\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\nanodet\\lib\\site-packages\\torch\\serialization.py:795\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\nanodet\\lib\\site-packages\\torch\\serialization.py:1002\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1002\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '<'."
     ]
    }
   ],
   "source": [
    "# 이미지 처리 및 저장을 위한 함수 정의\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from spiga.inference.config import ModelConfig\n",
    "from spiga.inference.framework import SPIGAFramework\n",
    "from spiga.demo.visualize.plotter import Plotter\n",
    "\n",
    "def process_and_save_image(image_path, bbox_path, output_path):\n",
    "    # 이미지와 bbox 정보 로드\n",
    "    image = cv2.imread(image_path)\n",
    "    with open(bbox_path) as jsonfile:\n",
    "        bbox_data = json.load(jsonfile)\n",
    "    \n",
    "    # bbox가 없으면 처리 중단\n",
    "    if not bbox_data['bbox']:\n",
    "        print(f\"No bbox found for {image_path}\")\n",
    "        return\n",
    "\n",
    "    canvas = image.copy()\n",
    "    \n",
    "    # SPIGA 프로세스 실행 (모든 bbox 처리)\n",
    "    for bbox in bbox_data['bbox']:\n",
    "        # SPIGA 프로세스 실행\n",
    "        dataset = 'wflw'\n",
    "        processor = SPIGAFramework(ModelConfig(dataset))\n",
    "        features = processor.inference(image, [bbox])\n",
    "        \n",
    "        # 결과 이미지 준비\n",
    "        x0, y0, w, h = bbox\n",
    "        landmarks = np.array(features['landmarks'][0])\n",
    "        headpose = np.array(features['headpose'][0])\n",
    "        \n",
    "        # 특징 시각화\n",
    "        plotter = Plotter()\n",
    "        canvas = plotter.landmarks.draw_landmarks(canvas, landmarks)\n",
    "        canvas = plotter.hpose.draw_headpose(canvas, [x0, y0, x0 + w, y0 + h], headpose[:3], headpose[3:], euler=True)\n",
    "    \n",
    "    # 결과 이미지 저장\n",
    "    cv2.imwrite(output_path, canvas)\n",
    "\n",
    "# 입력 및 출력 폴더 설정\n",
    "input_folder = 'omg_1min'\n",
    "bbox_data_folder = 'bbox_data'\n",
    "output_folder = 'processed_images'  # 처리된 이미지를 저장할 폴더\n",
    "\n",
    "# 출력 폴더가 없으면 생성\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# bbox data 입력 폴더에서 JSON 파일 목록 가져오기\n",
    "bbox_files = [f for f in os.listdir(bbox_data_folder) if f.endswith('.json')]\n",
    "\n",
    "# 이미지 입력 폴더에서 jpg 파일 목록 가져오기\n",
    "img_files = [f for f in os.listdir(input_folder) if f.endswith('.jpg')]\n",
    "\n",
    "# 각 bbox 파일에 대한 처리\n",
    "for img_file in img_files:\n",
    "    bbox_file = img_file.replace('jpg', 'json')\n",
    "    process_and_save_image(os.path.join(input_folder, img_file),\n",
    "                           os.path.join(bbox_data_folder, bbox_file),\n",
    "                           os.path.join(output_folder, img_file))\n",
    "\n",
    "print(\"모든 이미지의 처리 및 저장이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c88a798-718d-4b4e-9867-ae2f1dd1f08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.3\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b74e92-28d6-4138-9242-e53c02ce02d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swcap",
   "language": "python",
   "name": "nanodet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
